{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0a54210"
      },
      "source": [
        "## Upload data under data/ and hts_utils.py under utils/"
      ],
      "id": "c0a54210"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcykmCvNUmgI"
      },
      "source": [
        "This notebook was heavily modified from here:\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/Nixtla/hierarchicalforecast/blob/main/nbs/examples/NonNegativeReconciliation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "id": "jcykmCvNUmgI"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "7f777bdd-dff4-4bc0-8529-b492874de6f0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install hierarchicalforecast statsforecast"
      ],
      "id": "7f777bdd-dff4-4bc0-8529-b492874de6f0"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "51af708b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from utils.hts_eda_utils import *\n",
        "\n",
        "from hierarchicalforecast.utils import HierarchicalPlot\n",
        "from statsforecast.models import * # ARIMA, ETS, etc.\n",
        "from statsforecast.core import StatsForecast\n",
        "\n",
        "# TODO TopDown() reconciler causes KeyError 'ETS, Naive'. Same with Empirical Risk Minimization. Why?\n",
        "from hierarchicalforecast.methods import * # Reconcialiation methods: BottomUp, TopDown, MinTrace etc.\n",
        "from hierarchicalforecast.core import HierarchicalReconciliation\n",
        "\n",
        "from hierarchicalforecast.evaluation import HierarchicalEvaluation"
      ],
      "id": "51af708b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZaCmPwQTsQW",
        "outputId": "7ba91062-6ea7-49fb-943f-bde7523579e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsforecast/models.py:732: FutureWarning: `ETS` will be deprecated in future versions of `StatsForecast`. Please use `AutoETS` instead.\n",
            "  ETS._warn()\n"
          ]
        }
      ],
      "source": [
        "# dataset subset to use? # Use full initially\n",
        "#     deal_w_zeros_method = remove_zero_columns(df, any_or_all='any')\n",
        "\n",
        "SELECT_TOP_K_PRODUCTS = None # None = keep all\n",
        "\n",
        "\n",
        "# CHOOSE TIME SERIES METHODS HERE! https://nixtla.github.io/statsforecast/src/core/models_intro.html\n",
        "TSModels = [\n",
        "    ETS(season_length=7, model='ZAA'),\n",
        "    Naive(),\n",
        "    AutoETS(season_length=7, model='ZAA'),\n",
        "    ARIMA(),\n",
        "    SeasonalExponentialSmoothingOptimized(season_length=7),\n",
        "    AutoRegressive(lags=6),\n",
        "    RandomWalkWithDrift()\n",
        "    ]\n",
        "\n",
        "# https://nixtla.github.io/hierarchicalforecast/methods.html\n",
        "reconciliation_methods = [\n",
        "    BottomUp(),\n",
        "    TopDown(method='forecast_proportions'), # 'average_proportions' causes KeyError below\n",
        "    MinTrace(method='wls_struct'), # Ols seems to not converge (SVD error)\n",
        "    OptimalCombination(method='ols'), # Same\n",
        "    # ERM(method='closed') # Empirical Risk Minimization - KeyError\n",
        "]\n",
        "\n",
        "TIME_SERIES_FREQ = 'M'\n",
        "df = pd.read_excel('data/Quarterly_smoothing.xlsx', index_col=0)#.iloc[:,:5])"
      ],
      "id": "AZaCmPwQTsQW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B88cc41sMEyr"
      },
      "outputs": [],
      "source": [
        "dataset_hierarchy_delimiter = ' - ' # The delimiter currently used in the dataset\n",
        "HIERARCHY_DELIMITER = '_' # '_' is needed by HierarchicalForecast. Need to replace"
      ],
      "id": "B88cc41sMEyr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a910ea0"
      },
      "source": [
        "## 1. Load Data"
      ],
      "id": "2a910ea0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJO3_qHO8_mN"
      },
      "source": [
        "<font color='blue'>Ariel: Replace ` - ` with `_`. I think `_` is used as Hierarchy level split by HF package (not sure)</font>"
      ],
      "id": "mJO3_qHO8_mN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwL002u1FgHo"
      },
      "outputs": [],
      "source": [
        "df.columns = df.columns.str.replace(' - ', HIERARCHY_DELIMITER) # Replace Hierarchy delimiter"
      ],
      "id": "PwL002u1FgHo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "764a4aae"
      },
      "source": [
        "##### Columns of all zeros cause errors (Division by zero in Covariance calc.). Need to fix"
      ],
      "id": "764a4aae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71cdf49a"
      },
      "outputs": [],
      "source": [
        "# TODO make this transform a parameter too\n",
        "df = add_1_to_all_df_cells(df)\n",
        "\n",
        "df.head()"
      ],
      "id": "71cdf49a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c2185c1"
      },
      "source": [
        "##### Optional: Select only top Products\n",
        "\n",
        "Saves compute"
      ],
      "id": "6c2185c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpUI6D2HOgX_"
      },
      "outputs": [],
      "source": [
        "if SELECT_TOP_K_PRODUCTS is not None:\n",
        "    df = select_top_n_brands(df, n=SELECT_TOP_K_PRODUCTS)\n",
        "\n",
        "# df.head(5)"
      ],
      "id": "JpUI6D2HOgX_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2WyxjjiGxKC"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "df_with_aggregates, hierarchy = prep_data_for_scikit_hts(df)\n",
        "\n",
        "df_with_aggregates.head(5)"
      ],
      "id": "W2WyxjjiGxKC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf8W_T54OclO"
      },
      "source": [
        "<font color='cyan'>HierarchicalForecast likes data to be Drug | Date | Sales, rather than having DrugName as columns</font>\n",
        "\n",
        "\n",
        "### Melt data into format required by HierarchicalForecast\n",
        "\n",
        "Following how their example code's data looks"
      ],
      "id": "Pf8W_T54OclO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVNVuErdNqrf"
      },
      "outputs": [],
      "source": [
        "# Melt the DataFrame - convert ColNames to rows to match input to HierForecast\n",
        "df_with_aggregates.reset_index(inplace=True) # Move Month index to column (package requirement)\n",
        "\n",
        "# TODO Check these for prediction error\n",
        "melted_df = df_with_aggregates.melt(id_vars=['Month'], var_name='Drug', value_name='Sales')\n",
        "\n",
        "# Convert melted DataFrame to the required format\n",
        "melted_df = melted_df[['Drug', 'Month', 'Sales']]\n",
        "\n",
        "# Col names seem to need to be thus for package\n",
        "melted_df.rename(columns={'Drug': 'unique_id', 'Month':'ds', 'Sales':'y'}, inplace=True)\n",
        "\n",
        "\n",
        "print(melted_df.head())\n",
        "print(melted_df.tail())\n"
      ],
      "id": "qVNVuErdNqrf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kuum0MFCs_o"
      },
      "source": [
        "### Creating `S_df`\n",
        "\n",
        "All colored font is Ariel\n",
        "\n",
        "<font color='turquoise'>We've created `Y_df, tags`. All we need is `S_df`</font>\n",
        "This is like a tree representing the hierarchy, with aggregations at each level\n",
        "\n",
        "<font color='blue'>`S_df` is a representation of the Hierarchy - 1 means that column name (item, Drugs in our case), belongs to the Total row. Rows represent totals at each level of the hierarchy, for each node</font>"
      ],
      "id": "0Kuum0MFCs_o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfHLMVaDtnEx"
      },
      "outputs": [],
      "source": [
        "S_df = create_S_df(df)\n",
        "\n",
        "S_df"
      ],
      "id": "FfHLMVaDtnEx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtUguNs09xmE"
      },
      "source": [
        "### Create `tags`, which is a description of the Hierarchy as `dict`\n",
        "\n",
        "Original `tags` loaded from example Dataset - they didn't create it programmatically"
      ],
      "id": "vtUguNs09xmE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlVTOnCmHIjO"
      },
      "outputs": [],
      "source": [
        "# hierarchy"
      ],
      "id": "dlVTOnCmHIjO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F0EQvHuYvnA"
      },
      "outputs": [],
      "source": [
        "# TODO wtf did chatgpt do here?\n",
        "transformed_data = { # Need names for hierarchy levels IMO\n",
        "    \"Sales\": [\"Total\"],\n",
        "    \"Sales/Region\": hierarchy['Total'],\n",
        "    \"Sales/Region/DrugName\": sum([hierarchy[region] for region in hierarchy['Total']], []),\n",
        "    \"Sales/Region/DrugName/DrugDosage\": sum([hierarchy[key] for key in sum([hierarchy[region] for region in hierarchy['Total']], [])], []),\n",
        "}\n",
        "\n",
        "# Convert the lists to numpy arrays for consistency with the format\n",
        "for key in transformed_data:\n",
        "    transformed_data[key] = np.array(transformed_data[key], dtype=object)\n",
        "\n",
        "# print(transformed_data)\n",
        "tags = transformed_data"
      ],
      "id": "6F0EQvHuYvnA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56a7aadb-6e2c-456a-a0b5-b29b30deadb5"
      },
      "source": [
        "We split the dataframe in train/test splits."
      ],
      "id": "56a7aadb-6e2c-456a-a0b5-b29b30deadb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FZ9L2tnPzmW"
      },
      "outputs": [],
      "source": [
        "Y_df = melted_df\n",
        "\n",
        "# Y_df"
      ],
      "id": "0FZ9L2tnPzmW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "462451d8-2fc0-445e-9458-908811011dd9"
      },
      "outputs": [],
      "source": [
        "Y_test_df = Y_df.groupby('unique_id').tail(7) # Original code\n",
        "Y_train_df = Y_df.drop(Y_test_df.index)\n",
        "\n",
        "Y_test_df = Y_test_df.set_index('unique_id')\n",
        "Y_train_df = Y_train_df.set_index('unique_id')"
      ],
      "id": "462451d8-2fc0-445e-9458-908811011dd9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHADutcWGQRv"
      },
      "outputs": [],
      "source": [
        "print(Y_test_df.head())\n",
        "print(Y_test_df.tail())"
      ],
      "id": "IHADutcWGQRv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6eb7b54"
      },
      "source": [
        "## 2. Base Forecasts"
      ],
      "id": "c6eb7b54"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7cfb43a-cd16-418c-a04b-e075c176cc9e"
      },
      "source": [
        "The following cell computes the *base forecast* for each time series using the `ETS` and `naive` models. Observe that `Y_hat_df` contains the forecasts but they are not coherent."
      ],
      "id": "b7cfb43a-cd16-418c-a04b-e075c176cc9e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f99e7b7b-f4b8-4f2f-a1a7-c8be98a1e280"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "fcst = StatsForecast(\n",
        "    df=Y_train_df,\n",
        "    # models=TSModels,\n",
        "    models=[ETS(season_length=7, model='ZZA'), Naive()],\n",
        "    freq=TIME_SERIES_FREQ,\n",
        "    n_jobs=-1\n",
        ")\n",
        "Y_hat_df = fcst.forecast(h=7) # TODO What is h=7?"
      ],
      "id": "f99e7b7b-f4b8-4f2f-a1a7-c8be98a1e280"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FUw0Gxdc--lF"
      },
      "outputs": [],
      "source": [
        "TSModels"
      ],
      "id": "FUw0Gxdc--lF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oUHh732j_BzM"
      },
      "outputs": [],
      "source": [
        "[ETS(season_length=7, model='ZZA'), Naive()]# == TSModels"
      ],
      "id": "oUHh732j_BzM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eb06be5-1bf1-4e4f-90ad-4e635dacd640"
      },
      "source": [
        "Observe that the ETS model computes negative forecasts for some series."
      ],
      "id": "8eb06be5-1bf1-4e4f-90ad-4e635dacd640"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27YAtIhf2CFs"
      },
      "source": [
        "<font color='pink'>Does `Y_hat_df` have a `ds` column in the original code?</font>\n",
        "\n",
        "Yes"
      ],
      "id": "27YAtIhf2CFs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qKO_sp7O9dwL"
      },
      "outputs": [],
      "source": [
        "# Make sure S_df does not have extra entries - TODO I still don't know exactly how S_df is created\n",
        "#   This is jerry-rigged to work\n",
        "rows_to_drop = list(set(S_df.index) - set(Y_test_df.index))\n",
        "# rows_to_drop\n",
        "S_df.drop(rows_to_drop, inplace=True)"
      ],
      "id": "qKO_sp7O9dwL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FJ3vXSl2FQIG"
      },
      "outputs": [],
      "source": [
        "# `S_df` should have 1 entry for each unique row in `Y_hat_df`\n",
        "assert(len(S_df.index) == len(set(Y_hat_df.index)))\n",
        "assert(set(Y_train_df.index) - set(S_df.index) == set())\n",
        "assert(set(S_df.index) - set(Y_train_df.index) == set())"
      ],
      "id": "FJ3vXSl2FQIG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "752a0a14"
      },
      "source": [
        "## 3. Non-Negative Reconciliation"
      ],
      "id": "752a0a14"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc296762-2009-4aef-8b31-f24aad9d0787"
      },
      "source": [
        "The following cell makes the previous forecasts coherent and nonnegative using the `HierarchicalReconciliation` class."
      ],
      "id": "cc296762-2009-4aef-8b31-f24aad9d0787"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j3DQesAyT-xk"
      },
      "outputs": [],
      "source": [
        "hrec = HierarchicalReconciliation(reconcilers=[ERM(method='closed')])\n",
        "\n",
        "\n",
        "Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_train_df,\n",
        "                          S=S_df, tags=tags)\n",
        "\n",
        "Y_rec_df.head()"
      ],
      "id": "j3DQesAyT-xk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21a82e2b-03b6-4c0d-ac0c-5fdcca7572f2"
      },
      "source": [
        "Observe that the nonnegative reconciliation method obtains nonnegative forecasts."
      ],
      "id": "21a82e2b-03b6-4c0d-ac0c-5fdcca7572f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55edb754"
      },
      "source": [
        "## 4. Evaluation"
      ],
      "id": "55edb754"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03c4752c-53f8-4b1f-8169-32075b8e4050"
      },
      "source": [
        "The `HierarchicalForecast` package includes the `HierarchicalEvaluation` class to evaluate the different hierarchies and also is capable of compute scaled metrics compared to a benchmark model."
      ],
      "id": "03c4752c-53f8-4b1f-8169-32075b8e4050"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a793cff0-e6bf-469d-86d8-cf6ce7a8d922"
      },
      "outputs": [],
      "source": [
        "# TODO enhance this\n",
        "def mse(y, y_hat):\n",
        "    return np.mean((y-y_hat)**2)\n",
        "\n",
        "evaluator = HierarchicalEvaluation(evaluators=[mse])\n",
        "evaluation = evaluator.evaluate(\n",
        "        Y_hat_df=Y_rec_df, Y_test_df=Y_test_df,\n",
        "        tags=tags, benchmark='Naive'\n",
        ")\n",
        "evaluation.filter(like='ETS', axis=1).T"
      ],
      "id": "a793cff0-e6bf-469d-86d8-cf6ce7a8d922"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c16f960d-77c9-4acc-8438-ee14bf738cf7"
      },
      "source": [
        "Observe that the nonnegative reconciliation method performs better that its unconstrained counterpart."
      ],
      "id": "c16f960d-77c9-4acc-8438-ee14bf738cf7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHv9H64l4U99"
      },
      "source": [
        "## Plot Hierarchy & Evaluations"
      ],
      "id": "hHv9H64l4U99"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gjayg2u7-p6c"
      },
      "outputs": [],
      "source": [
        "a = Y_test_df.sort_index()#.sort_values(by='ds', ascending=True)\n",
        "\n",
        "# TODO programmatically get these by subtracting column names (set)\n",
        "b = Y_rec_df[['ETS', 'Naive', 'ETS/BottomUp', 'Naive/BottomUp']].sort_index()#.sort_values(by='ds', ascending=True)#.drop(columns=['ds'])\n",
        "\n",
        "b"
      ],
      "id": "gjayg2u7-p6c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zQF4Ng_3EEdi"
      },
      "outputs": [],
      "source": [
        "merged_test_preds_df = pd.concat([a, b], axis=1)\n",
        "# merged_test_preds_df"
      ],
      "id": "zQF4Ng_3EEdi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CsMVk5EREcIT"
      },
      "outputs": [],
      "source": [
        "merged_test_preds_df = merged_test_preds_df.sort_values(by='ds', ascending=True)\n",
        "merged_test_preds_df"
      ],
      "id": "CsMVk5EREcIT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FEnuvBth4WTL"
      },
      "outputs": [],
      "source": [
        "hplt = HierarchicalPlot(S=S_df, tags=tags)\n",
        "\n",
        "hplt.plot_hierarchical_predictions_gap(Y_df=merged_test_preds_df, models = 'ETS')#['ETS', 'Naive', 'ETS/BottomUp', 'Naive/BottomUp'])"
      ],
      "id": "FEnuvBth4WTL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DXI1gdZ_464Q"
      },
      "outputs": [],
      "source": [
        "hplt.plot_hierarchically_linked_series(bottom_series='Южный ФО_VALZ_Valz N FC tabs 80 mg/12.5mg #28', Y_df=Y_train_df)"
      ],
      "id": "DXI1gdZ_464Q"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a51830f5"
      },
      "source": [
        "### References\n",
        "- [Hyndman, R.J., & Athanasopoulos, G. (2021). \"Forecasting: principles and practice, 3rd edition:\n",
        "Chapter 11: Forecasting hierarchical and grouped series.\". OTexts: Melbourne, Australia. OTexts.com/fpp3\n",
        "Accessed on July 2022.](https://otexts.com/fpp3/hierarchical.html)\n",
        "- [Wickramasuriya, S. L., Athanasopoulos, G., & Hyndman, R. J. (2019). \\\"Optimal forecast reconciliation for\n",
        "    hierarchical and grouped time series through trace minimization\\\". Journal of the American Statistical Association,\n",
        "    114 , 804–819. doi:10.1080/01621459.2018.1448825.](https://robjhyndman.com/publications/mint/).\n",
        "- [Wickramasuriya, S.L., Turlach, B.A. & Hyndman, R.J. (2020). \\\"Optimal non-negative\n",
        "    forecast reconciliation\". Stat Comput 30, 1167–1182,\n",
        "    https://doi.org/10.1007/s11222-020-09930-0](https://robjhyndman.com/publications/nnmint/)."
      ],
      "id": "a51830f5"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}